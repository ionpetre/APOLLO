{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:32:51.538029Z",
     "start_time": "2022-10-21T17:32:51.462961Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "\n",
    "import os, gc\n",
    "import numpy as np\n",
    "#import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "np.set_printoptions(suppress=True, precision = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes \n",
    "\n",
    "## Model architecture \n",
    "We train a random forest classifier, using a 5-fold cross-validation. The validation folds are designed using over-sampling so that in each fold, the validation set contains at least one tumor from each class, but possibly more so that each class has at least 15% of its data in validation. \n",
    "\n",
    "We select the most important features from the random forest model for experimental validation. We also use them to train a support vector classifier model, to boost the quality of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-24T08:25:56.536345Z",
     "start_time": "2022-10-24T08:25:56.522936Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA DESCRIPTION\n",
    "Indicate the file names for the pre-processed data and for the tumor/non-tumor map. \n",
    "The pre-processed data is a list of dictionaries, one for each sample, each dictionary has the 2D x 1738 data\n",
    "plus its methylation label, sample name, patient ID, , t-SNE and PCA decompositions (datastructure described below).\n",
    "The tumor/non-tumor map is a list of numpy arrays, one for each sample, of the same 2D shape as the \n",
    "corresponding sample, coming in the same order as the samples in the pre-processed file. \n",
    "Each entry in the 2D array is 0/1, with 1 indicating that the corresponding spot in the pre-processed data \n",
    "was labeled as tumor. \n",
    "The map is to be used as filter: only those spot labeled as tumor are to be analysed further. \n",
    "We also use the map to extract the most discriminative features between tumor and non-tumor. \n",
    "\"\"\"\n",
    "\n",
    "PREPROC_DATA_PATH = \"../data/preprocessed.npy\"\n",
    "TUMOR_MAP_PATH = \"../data/tumor_maps.npy\"\n",
    "SEPARATION_CLASSIFIER_PATH = \"./TumorSeparationModels/\" \n",
    "\n",
    "# Make the directory if it doesn't exist\n",
    "if not os.path.exists(SEPARATION_CLASSIFIER_PATH[:-1]):\n",
    "    os.mkdir(SEPARATION_CLASSIFIER_PATH[:-1])\n",
    "\n",
    "SAMPLE_DICT_DATA_KEY = \"data\"\n",
    "SAMPLE_DICT_NAME_KEY = \"name\"\n",
    "SAMPLE_DICT_CLASS_ID_KEY = \"class_id\"\n",
    "SAMPLE_DICT_PATIENT_ID_KEY = \"patient_id\"\n",
    "SAMPLE_DICT_TSNE_KEY = \"tsne\"\n",
    "SAMPLE_DICT_PCA_KEY = \"pca\"\n",
    "\n",
    "# Define the samples to be excluded from the analysis (use their full name)\n",
    "ignore = [\"HF-1887_via-t_2_1.h5_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CROSS-VALIDATION DESIGN: 5-fold\n",
    "All samples (except 1887) included. Assigned to the CV folds in order of their names, \n",
    "trying to have about the same amount of validation data in each fold.\n",
    "Date: February 2023. \n",
    "\"\"\"\n",
    "\n",
    "CV5folds=[ \n",
    "    [#Cv fold 1\n",
    "        #LGm1 \n",
    "        \"HF-448_V5B_1.h5_3\",\n",
    "        #LGm2\n",
    "        \"HF-305_v4b_1_1.h5_6\", \"HF-615_V5BB_1.h5_9\",  \n",
    "        #LGm3\n",
    "        \"HF-2104_#5_1.h5_0\", \"HF-2104_#9_1.h5_1\", \"HF-2104_V1T_1.h5_2\",\n",
    "        #LGm4\n",
    "        \"HF-442_V4BB_1.h5_12\", \"HF-1002_V1AT_1.h5_0\", \"HF-1002_V2AT_1.h5_1\", \n",
    "        #LGm5\n",
    "        \"HF-682_V3AT_1.h5_9\", \"HF-682_V3BB_1.h5_10\", \"HF-894_9_1.h5_11\", \"HF-894_V1BB_1.h5_12\", \n",
    "        #LGm6\n",
    "        \"HF-592_V3T_1.h5_4\", \n",
    "    ],\n",
    "    [#Cv fold 2\n",
    "        #LGm1 \n",
    "        \"HF-868_1_2.h5_4\",\n",
    "        #LGm2\n",
    "        \"HF-901_V2T_2.h5_10\", \"HF-960_VIAT_2.h5_11\", \n",
    "        #LGm3\n",
    "        \"HF-2614_V1B_1.h5_3\", \n",
    "        #LGm4\n",
    "        \"HF-1825_V2B_1.h5_2\", \"HF-2102_V2BB_1.h5_3\", \"HF-2102_V3AM_1.h5_4\", \"HF-2102_V3AM_2.h5_5\", \n",
    "        #LGm5\n",
    "        \"HF-988_V1-T_1.h5_13\", \"HF-988_V1B_1.h5_14\", \"HF-1043_V1AM_1.h5_0\", \n",
    "        #LGm6\n",
    "        \"HF-2106_V3AM_1.h5_0\", \n",
    "    ], \n",
    "    [#Cv fold 3\n",
    "        #LGm1 \n",
    "        \"HF-1293_13_1.h5_0\",\n",
    "        #LGm2\n",
    "        \"HF-1010_V1T_1.h5_0\", \"HF-1016_IAT_2.h5_1\", \"HF-1334_V58-B_2_1.h5_2\", \n",
    "        #LGm3\n",
    "        \"HF-2849_VIT2_1.h5_4\", \"HF-2849_VIT2_1.h5_5\", \"HF-2849_VIT2_2.h5_6\", \"HF-2849_VIT_2_new2021.h5_7\",\n",
    "        #LGm4\n",
    "        \"HF-2454_V1AT_1.h5_6\", \"HF-2548_V1T_1.h5_7\", \n",
    "        #LGm5\n",
    "        \"HF-1086_#1_1.h5_1\", \"HF-2355_V2AM_1.h5_2\", \n",
    "        #LGm6\n",
    "        \"HF-2493_V1T_1.h5_1\", \"HF-2493_V1T_2.h5_2\", \n",
    "    ], \n",
    "    [#Cv fold 4\n",
    "        #LGm1 \n",
    "        \"HF-1295_V3AM_2.h5_1\",\n",
    "        #LGm2\n",
    "        \"HF-2070_V1T_1.h5_4\", \"HF-2776_V2B_2.h5_5\",        \n",
    "        #LGm3 \n",
    "        \"HF-2852_VIT_2_2.h5_8\", \n",
    "        #LGm4\n",
    "        \"HF-2715_VIL_1.h5_8\", \"HF-2802_V3T_1.h5_9\", \n",
    "        #LGm5\n",
    "        \"HF-2485_V1B_1.h5_3\", \"HF-2600_V1B_1.h5_4\", \"HF-2608_V1T_1.h5_5\", \n",
    "        #LGm6\n",
    "        \"HF-2544_V1B_1.h5_3\", \n",
    "    ],\n",
    "    [#Cv fold 5\n",
    "        #LGm1 \n",
    "        \"HF-2534_V2B_1.h5_2\",\n",
    "        #LGm2\n",
    "        \"HF-3271_VIB_2.h5_7\", \"HF-3337_V3T_1.h5_8\", \n",
    "        #LGm3 same as fold 1\n",
    "        \"HF-2104_#5_1.h5_0\", \"HF-2104_#9_1.h5_1\", \"HF-2104_V1T_1.h5_2\",\n",
    "        #LGm4\n",
    "        \"HF-2876_V1T_1.h5_10\", \"HF-2898_V1T_1.h5_11\",\n",
    "        #LGm5\n",
    "        \"HF-2619_V1T_1.h5_6\", \"HF-2619_V4T_1.h5_7\", \"HF-2666_V2B_1.h5_8\",\n",
    "        #LGm6 same as fold 1\n",
    "        \"HF-592_V3T_1.h5_4\", \n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed(SEED = 0):\n",
    "    os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    \n",
    "reset_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(data, labels, CV_folds=CV5folds, verbose=False):\n",
    "    \"\"\" \n",
    "    This is the cross-validation training. \n",
    "    In each CV fold, the model is first trained, then the data reduced to its top 20 features\n",
    "    and the model is re-trained with an SVC. \n",
    "    This is in the hope of reducing the noise and getting a better fit.\n",
    "    We save all RF and SVC models, as well as their metrics. \n",
    "    \"\"\"\n",
    "    \n",
    "    results = []  \n",
    "    RFmetrics=[]\n",
    "    SVCmetrics=[]\n",
    "    index = 0\n",
    "    \n",
    "    # Loop through the CV folds\n",
    "    for valid_fold in CV_folds:\n",
    "        \n",
    "        index = index+1\n",
    "        if verbose: \n",
    "            print(\"Validation fold\", index)\n",
    "        CV_fold_name=str(index)\n",
    "\n",
    "        # Get the train/validation data for this CV fold\n",
    "        train_X=np.empty( (0,data[0][SAMPLE_DICT_DATA_KEY].shape[1]) )\n",
    "        train_y=np.empty( 0 )\n",
    "        valid_names=[]\n",
    "        valid_X=np.empty( (0,data[0][SAMPLE_DICT_DATA_KEY].shape[1]) )\n",
    "        valid_y=np.empty( 0 )\n",
    "        for (sample,label) in zip(data,labels): \n",
    "            if sample[SAMPLE_DICT_NAME_KEY] in valid_fold:\n",
    "                valid_names.append(sample[SAMPLE_DICT_NAME_KEY])\n",
    "                valid_X = np.append(valid_X, sample[SAMPLE_DICT_DATA_KEY], axis=0)\n",
    "                valid_y = np.append(valid_y, label, axis=0)\n",
    "            else: \n",
    "                train_X = np.append(train_X, sample[SAMPLE_DICT_DATA_KEY], axis=0)\n",
    "                train_y = np.append(train_y, label, axis=0)\n",
    "        if len(valid_names) != len(valid_fold):\n",
    "            print(\"Error in the design of CV fold (data not found):\", valid_fold)\n",
    "            sys.exit(-1)     \n",
    "        \n",
    "        # Create list of indices\n",
    "        shuffle = np.arange(len(train_X))\n",
    "        \n",
    "        # Numpy shuffle method performs shuffle in place\n",
    "        np.random.shuffle(shuffle)\n",
    "        \n",
    "        # Shuffle the training data\n",
    "        train_X = np.squeeze(train_X[shuffle])\n",
    "        train_y = np.squeeze(train_y[shuffle])\n",
    "        \n",
    "        # Create RF model and train to extract features\n",
    "        RFclf = RandomForestClassifier(n_estimators = 300,\n",
    "                            bootstrap = True,\n",
    "                            max_depth = 10,\n",
    "                            random_state=0,\n",
    "                            criterion = \"entropy\",\n",
    "                            class_weight = \"balanced_subsample\",\n",
    "                            warm_start = False,\n",
    "                            n_jobs = -1,\n",
    "                            min_samples_leaf = 50,\n",
    "                            min_samples_split = 50,\n",
    "                            max_features = \"sqrt\")\n",
    "                            \n",
    "\n",
    "        RFclf.fit(train_X, train_y)\n",
    "        \n",
    "        # Get accuracy on training and validation data\n",
    "        acc_train = RFclf.score(train_X, train_y)\n",
    "        acc_val = RFclf.score(valid_X, valid_y)\n",
    "        if verbose: \n",
    "            print(\"\\t RF model. Accuracy on train and valid: \", acc_train, acc_val)\n",
    "        \n",
    "        # Get prediction on the validation data\n",
    "        pred = RFclf.predict(valid_X)\n",
    "        \n",
    "        # Gather RF metrics\n",
    "        RFacc = balanced_accuracy_score(valid_y, pred)\n",
    "        RFroc_auc = roc_auc_score(valid_y, pred, average =None)\n",
    "        RFprec = precision_score(valid_y, pred, average =None)\n",
    "        RFrec = recall_score(valid_y, pred, average =None)\n",
    "        RFf1 = f1_score(valid_y, pred, average =None)\n",
    "        RFconf = confusion_matrix(valid_y, pred, normalize='true')\n",
    "        RFmetrics.append([RFacc, RFroc_auc, RFprec, RFrec, RFf1, RFconf])\n",
    "        \n",
    "        if verbose: \n",
    "            print(\"\\t RF accuracy: \", RFacc)\n",
    "            print(\"\\t RF AUROC:    \", RFroc_auc)\n",
    "            print(\"\\t RF precision:\", RFprec)\n",
    "            print(\"\\t RF recall:   \", RFrec)\n",
    "            print(\"\\t RF F1:       \", RFf1)\n",
    "            print(\"\\t RF confusion matrix:\\n\", RFconf)\n",
    "        \n",
    "        # Save the model\n",
    "        joblib.dump(RFclf, SEPARATION_CLASSIFIER_PATH+\"RF_\" + CV_fold_name + \".RFmod\")\n",
    "        \n",
    "    return RFmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample ignored: HF-1887_via-t_2_1.h5_3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the pre-processed data and the tumor map of each sample\n",
    "samples_0 = np.load(PREPROC_DATA_PATH, allow_pickle=True)\n",
    "tumor_map_0 = np.load(TUMOR_MAP_PATH, allow_pickle=True)\n",
    "\n",
    "samples = []\n",
    "tumor_map = []\n",
    "\n",
    "# Flatten the data (no spatial info needed here) and skip the samples on the \"ignore\" list\n",
    "for (sample, label) in zip(samples_0, tumor_map_0):\n",
    "    if sample[SAMPLE_DICT_NAME_KEY] in ignore:\n",
    "        print(\"Sample ignored:\", sample[SAMPLE_DICT_NAME_KEY])\n",
    "        continue\n",
    "        \n",
    "    sample[SAMPLE_DICT_DATA_KEY] = sample[SAMPLE_DICT_DATA_KEY].reshape(-1, sample[SAMPLE_DICT_DATA_KEY].shape[2])\n",
    "    label.resize(np.product(label.shape))    \n",
    "    samples.append(sample)\n",
    "    tumor_map.append(label)\n",
    "    \n",
    "del samples_0\n",
    "del tumor_map_0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation fold 1\n",
      "\t RF model. Accuracy on train and valid:  0.9923969421126085 0.9985002286236854\n",
      "\t RF accuracy:  0.9927493924833478\n",
      "\t RF AUROC:     0.9927493924833478\n",
      "\t RF precision: [0.997 0.999]\n",
      "\t RF recall:    [0.986 1.   ]\n",
      "\t RF F1:        [0.991 0.999]\n",
      "\t RF confusion matrix:\n",
      " [[0.986 0.014]\n",
      " [0.    1.   ]]\n",
      "Validation fold 2\n",
      "\t RF model. Accuracy on train and valid:  0.9918656407425298 0.9812899735895886\n",
      "\t RF accuracy:  0.9841547271140232\n",
      "\t RF AUROC:     0.9841547271140233\n",
      "\t RF precision: [0.848 0.999]\n",
      "\t RF recall:    [0.988 0.981]\n",
      "\t RF F1:        [0.912 0.99 ]\n",
      "\t RF confusion matrix:\n",
      " [[0.988 0.012]\n",
      " [0.019 0.981]]\n",
      "Validation fold 3\n",
      "\t RF model. Accuracy on train and valid:  0.9992323831943094 0.9587131232838927\n",
      "\t RF accuracy:  0.9286171136808127\n",
      "\t RF AUROC:     0.9286171136808127\n",
      "\t RF precision: [0.994 0.947]\n",
      "\t RF recall:    [0.859 0.998]\n",
      "\t RF F1:        [0.922 0.972]\n",
      "\t RF confusion matrix:\n",
      " [[0.859 0.141]\n",
      " [0.002 0.998]]\n",
      "Validation fold 4\n",
      "\t RF model. Accuracy on train and valid:  0.9916735318347653 0.998908335387541\n",
      "\t RF accuracy:  0.9972588357141856\n",
      "\t RF AUROC:     0.9972588357141856\n",
      "\t RF precision: [0.994 0.999]\n",
      "\t RF recall:    [0.995 0.999]\n",
      "\t RF F1:        [0.994 0.999]\n",
      "\t RF confusion matrix:\n",
      " [[0.995 0.005]\n",
      " [0.001 0.999]]\n",
      "Validation fold 5\n",
      "\t RF model. Accuracy on train and valid:  0.9921943592016255 0.9970463223110727\n",
      "\t RF accuracy:  0.995015717007983\n",
      "\t RF AUROC:     0.995015717007983\n",
      "\t RF precision: [0.953 1.   ]\n",
      "\t RF recall:    [0.993 0.997]\n",
      "\t RF F1:        [0.972 0.998]\n",
      "\t RF confusion matrix:\n",
      " [[0.993 0.007]\n",
      " [0.003 0.997]]\n"
     ]
    }
   ],
   "source": [
    "reset_seed(2022)\n",
    "RFmetrics = CrossValidation(data=samples, labels=tumor_map, CV_folds=CV5folds, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del samples\n",
    "del tumor_map\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Mean RF accuracy:  0.9795591572000705\n",
      "\t Mean RF ROCAUC:    0.9795591572000705\n",
      "\t Mean RF precision: [0.957 0.989]\n",
      "\t Mean RF recall:    [0.964 0.995]\n",
      "\t Mean RF F1:        [0.958 0.992]\n",
      "\t Mean RF confusion matrix:\n",
      " [[0.964 0.036]\n",
      " [0.005 0.995]]\n"
     ]
    }
   ],
   "source": [
    "results = np.mean(np.asanyarray(RFmetrics, dtype=object), axis=0)\n",
    "print(\"\\t Mean RF accuracy: \", results[0])\n",
    "print(\"\\t Mean RF ROCAUC:   \", results[1])\n",
    "print(\"\\t Mean RF precision:\", results[2])\n",
    "print(\"\\t Mean RF recall:   \", results[3])\n",
    "print(\"\\t Mean RF F1:       \", results[4])\n",
    "print(\"\\t Mean RF confusion matrix:\\n\", results[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
