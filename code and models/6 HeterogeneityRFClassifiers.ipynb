{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:32:51.538029Z",
     "start_time": "2022-10-21T17:32:51.462961Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "\n",
    "import os, gc\n",
    "import numpy as np\n",
    "#import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "np.set_printoptions(suppress=True, precision = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes \n",
    "\n",
    "## Model architecture \n",
    "We train a random forest classifier, using a 5-fold cross-validation. The validation folds are designed using over-sampling so that in each fold, the validation set contains at least one tumor from each class, but possibly more so that each class has at least 15% of its data in validation. \n",
    "\n",
    "We select the most important features from the random forest model for experimental validation. We also use them to train a support vector classifier model, to boost the quality of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-24T08:25:56.536345Z",
     "start_time": "2022-10-24T08:25:56.522936Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA DESCRIPTION\n",
    "Indicate the file names for the pre-processed data and for the tumor/non-tumor map. \n",
    "The pre-processed data is a list of dictionaries, one for each sample, each dictionary has the 2D x 1738 data\n",
    "plus its methylation label, sample name, patient ID, , t-SNE and PCA decompositions (datastructure described below).\n",
    "The tumor/non-tumor map is a list of numpy arrays, one for each sample, of the same 2D shape as the \n",
    "corresponding sample, coming in the same order as the samples in the pre-processed file. \n",
    "Each entry in the 2D array is 0/1, with 1 indicating that the corresponding spot in the pre-processed data \n",
    "was labeled as tumor. \n",
    "The map is to be used as filter: only those spot labeled as tumor are to be analysed further. \n",
    "We also use the map to extract the most discriminative features between tumor and non-tumor. \n",
    "\"\"\"\n",
    "\n",
    "PREPROC_DATA_PATH = \"../data/preprocessed.npy\"\n",
    "TUMOR_MAP_PATH = \"../data/tumor_maps.npy\"\n",
    "\n",
    "BINARY_CLUSTER_PATH = \"../data/BinaryClusters.job\"\n",
    "SIX_CLUSTER_PATH = \"../data/SixClusters.job\"\n",
    "\n",
    "TWO_CLUSTER_CLASSIFIER_PATH = \"./2HeterogeneityRFModels/\"\n",
    "SIX_CLUSTER_CLASSIFIER_PATH = \"./6HeterogeneityRFModels/\"\n",
    "\n",
    "# Make the directory if it doesn't exist\n",
    "if not os.path.exists(TWO_CLUSTER_CLASSIFIER_PATH[2:-1]):\n",
    "    os.mkdir(TWO_CLUSTER_CLASSIFIER_PATH[2:-1])\n",
    "    \n",
    "# Make the directory if it doesn't exist\n",
    "if not os.path.exists(SIX_CLUSTER_CLASSIFIER_PATH[2:-1]):\n",
    "    os.mkdir(SIX_CLUSTER_CLASSIFIER_PATH[2:-1])\n",
    "\n",
    "SAMPLE_DICT_DATA_KEY = \"data\"\n",
    "SAMPLE_DICT_NAME_KEY = \"name\"\n",
    "SAMPLE_DICT_CLASS_ID_KEY = \"class_id\"\n",
    "SAMPLE_DICT_PATIENT_ID_KEY = \"patient_id\"\n",
    "SAMPLE_DICT_TSNE_KEY = \"tsne\"\n",
    "SAMPLE_DICT_PCA_KEY = \"pca\"\n",
    "\n",
    "# Define the samples to be excluded from the analysis (use their full name)\n",
    "ignore = [\"HF-1887_via-t_2_1.h5_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CROSS-VALIDATION DESIGN: 5-fold\n",
    "All samples (except 1887) included. Assigned to the CV folds in order of their names, \n",
    "trying to have about the same amount of validation data in each fold.\n",
    "Date: February 2023. \n",
    "\"\"\"\n",
    "\n",
    "CV5folds=[ \n",
    "    [#Cv fold 1\n",
    "        #LGm1 \n",
    "        \"HF-448_V5B_1.h5_3\",\n",
    "        #LGm2\n",
    "        \"HF-305_v4b_1_1.h5_6\", \"HF-615_V5BB_1.h5_9\",  \n",
    "        #LGm3\n",
    "        \"HF-2104_#5_1.h5_0\", \"HF-2104_#9_1.h5_1\", \"HF-2104_V1T_1.h5_2\",\n",
    "        #LGm4\n",
    "        \"HF-442_V4BB_1.h5_12\", \"HF-1002_V1AT_1.h5_0\", \"HF-1002_V2AT_1.h5_1\", \n",
    "        #LGm5\n",
    "        \"HF-682_V3AT_1.h5_9\", \"HF-682_V3BB_1.h5_10\", \"HF-894_9_1.h5_11\", \"HF-894_V1BB_1.h5_12\", \n",
    "        #LGm6\n",
    "        \"HF-592_V3T_1.h5_4\", \n",
    "    ],\n",
    "    [#Cv fold 2\n",
    "        #LGm1 \n",
    "        \"HF-868_1_2.h5_4\",\n",
    "        #LGm2\n",
    "        \"HF-901_V2T_2.h5_10\", \"HF-960_VIAT_2.h5_11\", \n",
    "        #LGm3\n",
    "        \"HF-2614_V1B_1.h5_3\", \n",
    "        #LGm4\n",
    "        \"HF-1825_V2B_1.h5_2\", \"HF-2102_V2BB_1.h5_3\", \"HF-2102_V3AM_1.h5_4\", \"HF-2102_V3AM_2.h5_5\", \n",
    "        #LGm5\n",
    "        \"HF-988_V1-T_1.h5_13\", \"HF-988_V1B_1.h5_14\", \"HF-1043_V1AM_1.h5_0\", \n",
    "        #LGm6\n",
    "        \"HF-2106_V3AM_1.h5_0\", \n",
    "    ], \n",
    "    [#Cv fold 3\n",
    "        #LGm1 \n",
    "        \"HF-1293_13_1.h5_0\",\n",
    "        #LGm2\n",
    "        \"HF-1010_V1T_1.h5_0\", \"HF-1016_IAT_2.h5_1\", \"HF-1334_V58-B_2_1.h5_2\", \n",
    "        #LGm3\n",
    "        \"HF-2849_VIT2_1.h5_4\", \"HF-2849_VIT2_1.h5_5\", \"HF-2849_VIT2_2.h5_6\", \"HF-2849_VIT_2_new2021.h5_7\",\n",
    "        #LGm4\n",
    "        \"HF-2454_V1AT_1.h5_6\", \"HF-2548_V1T_1.h5_7\", \n",
    "        #LGm5\n",
    "        \"HF-1086_#1_1.h5_1\", \"HF-2355_V2AM_1.h5_2\", \n",
    "        #LGm6\n",
    "        \"HF-2493_V1T_1.h5_1\", \"HF-2493_V1T_2.h5_2\", \n",
    "    ], \n",
    "    [#Cv fold 4\n",
    "        #LGm1 \n",
    "        \"HF-1295_V3AM_2.h5_1\",\n",
    "        #LGm2\n",
    "        \"HF-2070_V1T_1.h5_4\", \"HF-2776_V2B_2.h5_5\",        \n",
    "        #LGm3 \n",
    "        \"HF-2852_VIT_2_2.h5_8\", \n",
    "        #LGm4\n",
    "        \"HF-2715_VIL_1.h5_8\", \"HF-2802_V3T_1.h5_9\", \n",
    "        #LGm5\n",
    "        \"HF-2485_V1B_1.h5_3\", \"HF-2600_V1B_1.h5_4\", \"HF-2608_V1T_1.h5_5\", \n",
    "        #LGm6\n",
    "        \"HF-2544_V1B_1.h5_3\", \n",
    "    ],\n",
    "    [#Cv fold 5\n",
    "        #LGm1 \n",
    "        \"HF-2534_V2B_1.h5_2\",\n",
    "        #LGm2\n",
    "        \"HF-3271_VIB_2.h5_7\", \"HF-3337_V3T_1.h5_8\", \n",
    "        #LGm3 same as fold 1\n",
    "        \"HF-2104_#5_1.h5_0\", \"HF-2104_#9_1.h5_1\", \"HF-2104_V1T_1.h5_2\",\n",
    "        #LGm4\n",
    "        \"HF-2876_V1T_1.h5_10\", \"HF-2898_V1T_1.h5_11\",\n",
    "        #LGm5\n",
    "        \"HF-2619_V1T_1.h5_6\", \"HF-2619_V4T_1.h5_7\", \"HF-2666_V2B_1.h5_8\",\n",
    "        #LGm6 same as fold 1\n",
    "        \"HF-592_V3T_1.h5_4\", \n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed(SEED = 0):\n",
    "    os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "reset_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(data, labels, model_save_path, CV_folds=CV5folds, verbose=False):\n",
    "    \"\"\" \n",
    "    This is the cross-validation training. An RF classifier is trained in each fold.\n",
    "    \"\"\"\n",
    "    \n",
    "    RFmetrics=[]\n",
    "    index = 0\n",
    "    \n",
    "    # Loop through the CV folds\n",
    "    for valid_fold in CV_folds:\n",
    "        \n",
    "        index = index+1\n",
    "        if verbose: \n",
    "            print(\"Validation fold\", index)\n",
    "        CV_fold_name=str(index)\n",
    "\n",
    "        # Get the train/validation data for this CV fold\n",
    "        train_X=np.empty( (0,data[0][SAMPLE_DICT_DATA_KEY].shape[1]) )\n",
    "        train_y=np.empty( 0 )\n",
    "        valid_names=[]\n",
    "        valid_X=np.empty( (0,data[0][SAMPLE_DICT_DATA_KEY].shape[1]) )\n",
    "        valid_y=np.empty( 0 )\n",
    "        for (sample,label) in zip(data,labels): \n",
    "            if sample[SAMPLE_DICT_NAME_KEY] in valid_fold:\n",
    "                valid_names.append(sample[SAMPLE_DICT_NAME_KEY])\n",
    "                valid_X = np.append(valid_X, sample[SAMPLE_DICT_DATA_KEY], axis=0)\n",
    "                valid_y = np.append(valid_y, label, axis=0)\n",
    "            else: \n",
    "                train_X = np.append(train_X, sample[SAMPLE_DICT_DATA_KEY], axis=0)\n",
    "                train_y = np.append(train_y, label, axis=0)\n",
    "        if len(valid_names) != len(valid_fold):\n",
    "            print(\"Error in the design of CV fold (data not found):\", valid_fold)\n",
    "            sys.exit(-1)     \n",
    "            \n",
    "        # Create list of indices\n",
    "        shuffle = np.arange(len(train_X))\n",
    "        \n",
    "        # Numpy shuffle method performs shuffle in place\n",
    "        np.random.shuffle(shuffle)\n",
    "        \n",
    "        # Shuffle the training data\n",
    "        train_X = np.squeeze(train_X[shuffle])\n",
    "        train_y = np.squeeze(train_y[shuffle])\n",
    "    \n",
    "        # Create RF model and train to extract features\n",
    "        RFclf = RandomForestClassifier(n_estimators = 300,\n",
    "                            bootstrap = True,\n",
    "                            max_depth = 10,\n",
    "                            random_state=0,\n",
    "                            criterion = \"entropy\",\n",
    "                            class_weight = \"balanced_subsample\",\n",
    "                            warm_start = False,\n",
    "                            n_jobs = -1,\n",
    "                            min_samples_leaf = 50,\n",
    "                            min_samples_split = 50,\n",
    "                            max_features = \"sqrt\"\n",
    "                            )\n",
    "\n",
    "        RFclf.fit(train_X, train_y)\n",
    "        \n",
    "        # Get accuracy on training and validation data\n",
    "        acc_train = RFclf.score(train_X, train_y)\n",
    "        acc_val = RFclf.score(valid_X, valid_y)\n",
    "        if verbose: \n",
    "            print(\"\\t RF model. Accuracy on train and valid: \", acc_train, acc_val)\n",
    "        \n",
    "        # Get prediction on the validation data\n",
    "        pred = RFclf.predict(valid_X)\n",
    "        \n",
    "        # Gather RF metrics\n",
    "        RFacc = accuracy_score(valid_y, pred)\n",
    "        RFprec = precision_score(valid_y, pred, average = None)\n",
    "        RFrec = recall_score(valid_y, pred, average = None)\n",
    "        RFf1 = f1_score(valid_y, pred, average = None)\n",
    "        RFconf = confusion_matrix(valid_y, pred, normalize='true')\n",
    "        RFmetrics.append([RFacc, RFprec, RFrec, RFf1, RFconf])\n",
    "        \n",
    "        if verbose: \n",
    "            print(\"\\t RF accuracy: \", RFacc)\n",
    "            print(\"\\t RF precision:\", RFprec)\n",
    "            print(\"\\t RF recall:   \", RFrec)\n",
    "            print(\"\\t RF F1:       \", RFf1)\n",
    "            print(\"\\t RF confusion matrix:\\n\", RFconf)\n",
    "            \n",
    "        \n",
    "        # Save the model\n",
    "        joblib.dump(RFclf, model_save_path+\"RF_\" + CV_fold_name + \".RFmod\")        \n",
    "        \n",
    "        # Clear memory\n",
    "        del RFclf\n",
    "        del train_X\n",
    "        del train_y\n",
    "        del valid_X\n",
    "        del valid_y\n",
    "        gc.collect()\n",
    "        \n",
    "    return RFmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 2-cluster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample ignored: HF-1887_via-t_2_1.h5_3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the pre-processed data and the tumor map of each sample\n",
    "samples_0 = np.load(PREPROC_DATA_PATH, allow_pickle=True)\n",
    "tumor_map_0 = np.load(TUMOR_MAP_PATH, allow_pickle=True)\n",
    "\n",
    "# Read the clustering data. \n",
    "# It comes in the form a model, that offers the cluster label through its predict() function\n",
    "bin_clus = joblib.load(BINARY_CLUSTER_PATH)\n",
    "\n",
    "samples = []\n",
    "labels=[]\n",
    "\n",
    "for (sample, tumor) in zip(samples_0, tumor_map_0):\n",
    "    # Filter the data: retain only the tumor spots, based on the tumor map    \n",
    "    # Simultaneously, flatten the data (no spatial info needed here) \n",
    "    \n",
    "    # skip the samples on the \"ignore\" list\n",
    "    if sample[SAMPLE_DICT_NAME_KEY] in ignore:\n",
    "        print(\"Sample ignored:\", sample[SAMPLE_DICT_NAME_KEY])\n",
    "        continue\n",
    "    \n",
    "    sample[SAMPLE_DICT_DATA_KEY] = sample[SAMPLE_DICT_DATA_KEY].reshape(-1, sample[SAMPLE_DICT_DATA_KEY].shape[2])\n",
    "    tumor.resize(np.product(tumor.shape))\n",
    "    sample[SAMPLE_DICT_DATA_KEY] = sample[SAMPLE_DICT_DATA_KEY][tumor == 1]\n",
    "    samples.append(sample)\n",
    "    \n",
    "    # Get the clustering labels for the current sample\n",
    "    label = bin_clus.predict(sample[SAMPLE_DICT_DATA_KEY])\n",
    "    labels.append(label)\n",
    "    \n",
    "del samples_0\n",
    "del tumor_map_0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation fold 1\n",
      "\t RF model. Accuracy on train and valid:  0.9826069444512665 0.96617420683313\n",
      "\t RF accuracy:  0.96617420683313\n",
      "\t RF precision: [0.99  0.944]\n",
      "\t RF recall:    [0.943 0.99 ]\n",
      "\t RF F1:        [0.966 0.967]\n",
      "\t RF confusion matrix:\n",
      " [[0.943 0.057]\n",
      " [0.01  0.99 ]]\n",
      "Validation fold 2\n",
      "\t RF model. Accuracy on train and valid:  0.9821522869445122 0.9717104334321616\n",
      "\t RF accuracy:  0.9717104334321616\n",
      "\t RF precision: [0.98  0.959]\n",
      "\t RF recall:    [0.974 0.969]\n",
      "\t RF F1:        [0.977 0.964]\n",
      "\t RF confusion matrix:\n",
      " [[0.974 0.026]\n",
      " [0.031 0.969]]\n",
      "Validation fold 3\n",
      "\t RF model. Accuracy on train and valid:  0.9830954647983421 0.963223855552254\n",
      "\t RF accuracy:  0.963223855552254\n",
      "\t RF precision: [0.963 0.964]\n",
      "\t RF recall:    [0.971 0.953]\n",
      "\t RF F1:        [0.967 0.959]\n",
      "\t RF confusion matrix:\n",
      " [[0.971 0.029]\n",
      " [0.047 0.953]]\n",
      "Validation fold 4\n",
      "\t RF model. Accuracy on train and valid:  0.9821231865086618 0.9737917016827252\n",
      "\t RF accuracy:  0.9737917016827252\n",
      "\t RF precision: [0.986 0.963]\n",
      "\t RF recall:    [0.96  0.987]\n",
      "\t RF F1:        [0.973 0.975]\n",
      "\t RF confusion matrix:\n",
      " [[0.96  0.04 ]\n",
      " [0.013 0.987]]\n",
      "Validation fold 5\n",
      "\t RF model. Accuracy on train and valid:  0.9827943078913325 0.9728471536064452\n",
      "\t RF accuracy:  0.9728471536064452\n",
      "\t RF precision: [0.989 0.95 ]\n",
      "\t RF recall:    [0.964 0.985]\n",
      "\t RF F1:        [0.977 0.967]\n",
      "\t RF confusion matrix:\n",
      " [[0.964 0.036]\n",
      " [0.015 0.985]]\n"
     ]
    }
   ],
   "source": [
    "reset_seed(2022)\n",
    "RFmetrics = CrossValidation(data=samples, labels=labels, model_save_path=TWO_CLUSTER_CLASSIFIER_PATH, CV_folds=CV5folds, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del samples\n",
    "del labels\n",
    "del bin_clus\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Mean RF accuracy:  0.9695494702213432\n",
      "\t Mean RF precision: [0.982 0.956]\n",
      "\t Mean RF recall:    [0.962 0.977]\n",
      "\t Mean RF F1:        [0.972 0.966]\n",
      "\t Mean RF confusion matrix:\n",
      " [[0.962 0.038]\n",
      " [0.023 0.977]]\n"
     ]
    }
   ],
   "source": [
    "results = np.mean(np.asarray(RFmetrics,dtype=object), axis=0)\n",
    "print(\"\\t Mean RF accuracy: \", results[0])\n",
    "print(\"\\t Mean RF precision:\", results[1])\n",
    "print(\"\\t Mean RF recall:   \", results[2])\n",
    "print(\"\\t Mean RF F1:       \", results[3])\n",
    "print(\"\\t Mean RF confusion matrix:\\n\", results[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 6-cluster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample ignored: HF-1887_via-t_2_1.h5_3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the pre-processed data and the tumor map of each sample\n",
    "samples_0 = np.load(PREPROC_DATA_PATH, allow_pickle=True)\n",
    "tumor_map_0 = np.load(TUMOR_MAP_PATH, allow_pickle=True)\n",
    "\n",
    "# Read the clustering data. \n",
    "# It comes in the form a model, that offers the cluster label through its predict() function\n",
    "six_clus = joblib.load(SIX_CLUSTER_PATH)\n",
    "\n",
    "samples = []\n",
    "labels=[]\n",
    "\n",
    "for (sample, tumor) in zip(samples_0, tumor_map_0):\n",
    "    # Filter the data: retain only the tumor spots, based on the tumor map    \n",
    "    # Simultaneously, flatten the data (no spatial info needed here) \n",
    "    \n",
    "    # skip the samples on the \"ignore\" list\n",
    "    if sample[SAMPLE_DICT_NAME_KEY] in ignore:\n",
    "        print(\"Sample ignored:\", sample[SAMPLE_DICT_NAME_KEY])\n",
    "        continue    \n",
    "    \n",
    "    sample[SAMPLE_DICT_DATA_KEY] = sample[SAMPLE_DICT_DATA_KEY].reshape(-1, sample[SAMPLE_DICT_DATA_KEY].shape[2])\n",
    "    tumor.resize(np.product(tumor.shape))\n",
    "    sample[SAMPLE_DICT_DATA_KEY] = sample[SAMPLE_DICT_DATA_KEY][tumor == 1]\n",
    "    samples.append(sample)\n",
    "    \n",
    "    # Get the clustering labels for the current sample\n",
    "    label = six_clus.predict(sample[SAMPLE_DICT_DATA_KEY])\n",
    "    labels.append(label)\n",
    "    \n",
    "del samples_0\n",
    "del tumor_map_0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation fold 1\n",
      "\t RF model. Accuracy on train and valid:  0.9270925943208554 0.9027008656364327\n",
      "\t RF accuracy:  0.9027008656364327\n",
      "\t RF precision: [0.974 0.573 0.217 0.969 0.674 0.667]\n",
      "\t RF recall:    [0.868 0.993 0.963 0.918 0.731 0.997]\n",
      "\t RF F1:        [0.918 0.727 0.355 0.943 0.701 0.799]\n",
      "\t RF confusion matrix:\n",
      " [[0.868 0.019 0.058 0.045 0.01  0.   ]\n",
      " [0.007 0.993 0.    0.    0.    0.   ]\n",
      " [0.    0.    0.963 0.037 0.    0.   ]\n",
      " [0.013 0.    0.03  0.918 0.    0.039]\n",
      " [0.102 0.167 0.    0.    0.731 0.   ]\n",
      " [0.    0.    0.    0.003 0.    0.997]]\n",
      "Validation fold 2\n",
      "\t RF model. Accuracy on train and valid:  0.9115281501340483 0.9266377241281942\n",
      "\t RF accuracy:  0.9266377241281942\n",
      "\t RF precision: [0.934 0.48  0.149 0.977 0.909 0.899]\n",
      "\t RF recall:    [0.926 0.993 0.975 0.898 0.989 1.   ]\n",
      "\t RF F1:        [0.93  0.647 0.259 0.936 0.947 0.947]\n",
      "\t RF confusion matrix:\n",
      " [[0.926 0.019 0.011 0.022 0.022 0.   ]\n",
      " [0.    0.993 0.    0.    0.007 0.   ]\n",
      " [0.    0.    0.975 0.025 0.    0.   ]\n",
      " [0.062 0.    0.017 0.898 0.    0.023]\n",
      " [0.002 0.009 0.    0.    0.989 0.   ]\n",
      " [0.    0.    0.    0.    0.    1.   ]]\n",
      "Validation fold 3\n",
      "\t RF model. Accuracy on train and valid:  0.9269948115297076 0.8731537641362676\n",
      "\t RF accuracy:  0.8731537641362676\n",
      "\t RF precision: [0.92  0.268 0.259 0.979 0.692 0.737]\n",
      "\t RF recall:    [0.843 0.99  0.84  0.909 0.684 0.892]\n",
      "\t RF F1:        [0.88  0.422 0.396 0.943 0.688 0.807]\n",
      "\t RF confusion matrix:\n",
      " [[0.843 0.083 0.014 0.018 0.041 0.   ]\n",
      " [0.002 0.99  0.    0.    0.008 0.   ]\n",
      " [0.107 0.01  0.84  0.044 0.    0.   ]\n",
      " [0.05  0.    0.023 0.909 0.    0.018]\n",
      " [0.008 0.308 0.    0.    0.684 0.   ]\n",
      " [0.007 0.    0.    0.1   0.    0.892]]\n",
      "Validation fold 4\n",
      "\t RF model. Accuracy on train and valid:  0.9157433523841514 0.9389450231594583\n",
      "\t RF accuracy:  0.9389450231594583\n",
      "\t RF precision: [0.949 0.277 0.099 0.977 0.952 0.738]\n",
      "\t RF recall:    [0.934 0.974 1.    0.952 0.73  0.988]\n",
      "\t RF F1:        [0.942 0.432 0.18  0.964 0.826 0.845]\n",
      "\t RF confusion matrix:\n",
      " [[0.934 0.015 0.011 0.036 0.004 0.   ]\n",
      " [0.013 0.974 0.    0.    0.013 0.   ]\n",
      " [0.    0.    1.    0.    0.    0.   ]\n",
      " [0.017 0.    0.014 0.952 0.    0.017]\n",
      " [0.206 0.064 0.    0.    0.73  0.   ]\n",
      " [0.    0.    0.    0.012 0.    0.988]]\n",
      "Validation fold 5\n",
      "\t RF model. Accuracy on train and valid:  0.91677778883471 0.9193015125028502\n",
      "\t RF accuracy:  0.9193015125028502\n",
      "\t RF precision: [0.965 0.415 0.103 0.977 0.586 0.552]\n",
      "\t RF recall:    [0.914 1.    0.991 0.922 0.861 0.987]\n",
      "\t RF F1:        [0.939 0.586 0.186 0.948 0.697 0.708]\n",
      "\t RF confusion matrix:\n",
      " [[0.914 0.028 0.013 0.025 0.02  0.   ]\n",
      " [0.    1.    0.    0.    0.    0.   ]\n",
      " [0.009 0.    0.991 0.    0.    0.   ]\n",
      " [0.029 0.    0.026 0.922 0.    0.023]\n",
      " [0.008 0.131 0.    0.    0.861 0.   ]\n",
      " [0.    0.    0.    0.013 0.    0.987]]\n"
     ]
    }
   ],
   "source": [
    "reset_seed(2022)\n",
    "RFmetrics = CrossValidation(data=samples, labels=labels, model_save_path=SIX_CLUSTER_CLASSIFIER_PATH, CV_folds=CV5folds, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del samples\n",
    "del labels\n",
    "del six_clus\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Mean RF accuracy:  0.9121477779126405\n",
      "\t Mean RF precision: [0.949 0.403 0.165 0.976 0.763 0.719]\n",
      "\t Mean RF recall:    [0.897 0.99  0.954 0.92  0.799 0.973]\n",
      "\t Mean RF F1:        [0.922 0.563 0.275 0.947 0.772 0.821]\n",
      "\t Mean RF confusion matrix:\n",
      " [[0.897 0.033 0.021 0.029 0.019 0.   ]\n",
      " [0.004 0.99  0.    0.    0.006 0.   ]\n",
      " [0.023 0.002 0.954 0.021 0.    0.   ]\n",
      " [0.034 0.    0.022 0.92  0.    0.024]\n",
      " [0.065 0.136 0.    0.    0.799 0.   ]\n",
      " [0.001 0.    0.    0.026 0.    0.973]]\n"
     ]
    }
   ],
   "source": [
    "results = np.mean(np.asarray(RFmetrics,dtype=object), axis=0)\n",
    "print(\"\\t Mean RF accuracy: \", results[0])\n",
    "print(\"\\t Mean RF precision:\", results[1])\n",
    "print(\"\\t Mean RF recall:   \", results[2])\n",
    "print(\"\\t Mean RF F1:       \", results[3])\n",
    "print(\"\\t Mean RF confusion matrix:\\n\", results[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
