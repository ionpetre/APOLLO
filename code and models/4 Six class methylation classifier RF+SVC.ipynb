{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-21T17:32:51.538029Z",
     "start_time": "2022-10-21T17:32:51.462961Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "\n",
    "import os, gc\n",
    "import numpy as np\n",
    "#import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "np.set_printoptions(suppress=True, precision = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes \n",
    "\n",
    "## Model architecture \n",
    "We train a random forest classifier, using a 5-fold cross-validation. The validation folds are designed using over-sampling so that in each fold, the validation set contains at least one tumor from each class, but possibly more so that each class has at least 15% of its data in validation. \n",
    "\n",
    "We select the most important features from the random forest model for experimental validation. We also use them to train a support vector classifier model, to boost the quality of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-24T08:25:56.536345Z",
     "start_time": "2022-10-24T08:25:56.522936Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DATA DESCRIPTION\n",
    "Indicate the file names for the pre-processed data and for the tumor/non-tumor map. \n",
    "The pre-processed data is a list of dictionaries, one for each sample, each dictionary has the 2D x 1738 data\n",
    "plus its methylation label, sample name, patient ID, , t-SNE and PCA decompositions (datastructure described below).\n",
    "The tumor/non-tumor map is a list of numpy arrays, one for each sample, of the same 2D shape as the \n",
    "corresponding sample, coming in the same order as the samples in the pre-processed file. \n",
    "Each entry in the 2D array is 0/1, with 1 indicating that the corresponding spot in the pre-processed data \n",
    "was labeled as tumor. \n",
    "The map is to be used as filter: only those spot labeled as tumor are to be analysed further. \n",
    "We also use the map to extract the most discriminative features between tumor and non-tumor. \n",
    "\"\"\"\n",
    "\n",
    "PREPROC_DATA_PATH = \"../data/preprocessed.npy\"\n",
    "TUMOR_MAP_PATH = \"../data/tumor_maps.npy\"\n",
    "SIX_CLASSIFIER_PATH = \"./SixMethylModels/\"\n",
    "\n",
    "# Make the directory if it doesn't exist\n",
    "if not os.path.exists(SIX_CLASSIFIER_PATH[2:-1]):\n",
    "    os.mkdir(SIX_CLASSIFIER_PATH[2:-1])\n",
    "\n",
    "SAMPLE_DICT_DATA_KEY = \"data\"\n",
    "SAMPLE_DICT_NAME_KEY = \"name\"\n",
    "SAMPLE_DICT_CLASS_ID_KEY = \"class_id\"\n",
    "SAMPLE_DICT_PATIENT_ID_KEY = \"patient_id\"\n",
    "SAMPLE_DICT_TSNE_KEY = \"tsne\"\n",
    "SAMPLE_DICT_PCA_KEY = \"pca\"\n",
    "\n",
    "# Define the samples to be excluded from the analysis (use their full name)\n",
    "ignore = [\"HF-1887_via-t_2_1.h5_3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CROSS-VALIDATION DESIGN: 5-fold\n",
    "All samples (except 1887) included. Assigned to the CV folds in order of their names, \n",
    "trying to have about the same amount of validation data in each fold.\n",
    "Date: February 2023. \n",
    "\"\"\"\n",
    "\n",
    "CV5folds=[ \n",
    "    [#Cv fold 1\n",
    "        #LGm1 \n",
    "        \"HF-448_V5B_1.h5_3\",\n",
    "        #LGm2\n",
    "        \"HF-305_v4b_1_1.h5_6\", \"HF-615_V5BB_1.h5_9\",  \n",
    "        #LGm3\n",
    "        \"HF-2104_#5_1.h5_0\", \"HF-2104_#9_1.h5_1\", \"HF-2104_V1T_1.h5_2\",\n",
    "        #LGm4\n",
    "        \"HF-442_V4BB_1.h5_12\", \"HF-1002_V1AT_1.h5_0\", \"HF-1002_V2AT_1.h5_1\", \n",
    "        #LGm5\n",
    "        \"HF-682_V3AT_1.h5_9\", \"HF-682_V3BB_1.h5_10\", \"HF-894_9_1.h5_11\", \"HF-894_V1BB_1.h5_12\", \n",
    "        #LGm6\n",
    "        \"HF-592_V3T_1.h5_4\", \n",
    "    ],\n",
    "    [#Cv fold 2\n",
    "        #LGm1 \n",
    "        \"HF-868_1_2.h5_4\",\n",
    "        #LGm2\n",
    "        \"HF-901_V2T_2.h5_10\", \"HF-960_VIAT_2.h5_11\", \n",
    "        #LGm3\n",
    "        \"HF-2614_V1B_1.h5_3\", \n",
    "        #LGm4\n",
    "        \"HF-1825_V2B_1.h5_2\", \"HF-2102_V2BB_1.h5_3\", \"HF-2102_V3AM_1.h5_4\", \"HF-2102_V3AM_2.h5_5\", \n",
    "        #LGm5\n",
    "        \"HF-988_V1-T_1.h5_13\", \"HF-988_V1B_1.h5_14\", \"HF-1043_V1AM_1.h5_0\", \n",
    "        #LGm6\n",
    "        \"HF-2106_V3AM_1.h5_0\", \n",
    "    ], \n",
    "    [#Cv fold 3\n",
    "        #LGm1 \n",
    "        \"HF-1293_13_1.h5_0\",\n",
    "        #LGm2\n",
    "        \"HF-1010_V1T_1.h5_0\", \"HF-1016_IAT_2.h5_1\", \"HF-1334_V58-B_2_1.h5_2\", \n",
    "        #LGm3\n",
    "        \"HF-2849_VIT2_1.h5_4\", \"HF-2849_VIT2_1.h5_5\", \"HF-2849_VIT2_2.h5_6\", \"HF-2849_VIT_2_new2021.h5_7\",\n",
    "        #LGm4\n",
    "        \"HF-2454_V1AT_1.h5_6\", \"HF-2548_V1T_1.h5_7\", \n",
    "        #LGm5\n",
    "        \"HF-1086_#1_1.h5_1\", \"HF-2355_V2AM_1.h5_2\", \n",
    "        #LGm6\n",
    "        \"HF-2493_V1T_1.h5_1\", \"HF-2493_V1T_2.h5_2\", \n",
    "    ], \n",
    "    [#Cv fold 4\n",
    "        #LGm1 \n",
    "        \"HF-1295_V3AM_2.h5_1\",\n",
    "        #LGm2\n",
    "        \"HF-2070_V1T_1.h5_4\", \"HF-2776_V2B_2.h5_5\",        \n",
    "        #LGm3 \n",
    "        \"HF-2852_VIT_2_2.h5_8\", \n",
    "        #LGm4\n",
    "        \"HF-2715_VIL_1.h5_8\", \"HF-2802_V3T_1.h5_9\", \n",
    "        #LGm5\n",
    "        \"HF-2485_V1B_1.h5_3\", \"HF-2600_V1B_1.h5_4\", \"HF-2608_V1T_1.h5_5\", \n",
    "        #LGm6\n",
    "        \"HF-2544_V1B_1.h5_3\", \n",
    "    ],\n",
    "    [#Cv fold 5\n",
    "        #LGm1 \n",
    "        \"HF-2534_V2B_1.h5_2\",\n",
    "        #LGm2\n",
    "        \"HF-3271_VIB_2.h5_7\", \"HF-3337_V3T_1.h5_8\", \n",
    "        #LGm3 same as fold 1\n",
    "        \"HF-2104_#5_1.h5_0\", \"HF-2104_#9_1.h5_1\", \"HF-2104_V1T_1.h5_2\",\n",
    "        #LGm4\n",
    "        \"HF-2876_V1T_1.h5_10\", \"HF-2898_V1T_1.h5_11\",\n",
    "        #LGm5\n",
    "        \"HF-2619_V1T_1.h5_6\", \"HF-2619_V4T_1.h5_7\", \"HF-2666_V2B_1.h5_8\",\n",
    "        #LGm6 same as fold 1\n",
    "        \"HF-592_V3T_1.h5_4\", \n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed(SEED = 0):\n",
    "    os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "reset_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(data, labels, CV_folds=CV5folds, verbose=False):\n",
    "    \"\"\" \n",
    "    This is the cross-validation training. \n",
    "    In each CV fold, the model is first trained, then the data reduced to its top 20 features\n",
    "    and the model is re-trained with an SVC. \n",
    "    This is in the hope of reducing the noise and getting a better fit.\n",
    "    We save all RF and SVC models, as well as their metrics. \n",
    "    \"\"\"\n",
    "    \n",
    "    results = []  \n",
    "    RFmetrics=[]\n",
    "    SVCmetrics=[]\n",
    "    index = 0\n",
    "    \n",
    "    # Loop through the CV folds\n",
    "    for valid_fold in CV_folds:\n",
    "        \n",
    "        index = index+1\n",
    "        print(\"Validation fold\", index)\n",
    "        CV_fold_name=str(index)\n",
    "\n",
    "        # Get the train/validation data for this CV fold\n",
    "        train_X=np.empty( (0,data[0][SAMPLE_DICT_DATA_KEY].shape[1]) )\n",
    "        train_y=np.empty( 0 )\n",
    "        valid_names=[]\n",
    "        valid_X=np.empty( (0,data[0][SAMPLE_DICT_DATA_KEY].shape[1]) )\n",
    "        valid_y=np.empty( 0 )\n",
    "        for (sample,label) in zip(data,labels): \n",
    "            if sample[SAMPLE_DICT_NAME_KEY] in valid_fold:\n",
    "                valid_names.append(sample[SAMPLE_DICT_NAME_KEY])\n",
    "                valid_X = np.append(valid_X, sample[SAMPLE_DICT_DATA_KEY], axis=0)\n",
    "                valid_y = np.append(valid_y, label, axis=0)\n",
    "            else: \n",
    "                train_X = np.append(train_X, sample[SAMPLE_DICT_DATA_KEY], axis=0)\n",
    "                train_y = np.append(train_y, label, axis=0)\n",
    "        if len(valid_names) != len(valid_fold):\n",
    "            print(\"Error in the design of CV fold (data not found):\", valid_fold)\n",
    "            sys.exit(-1)     \n",
    "            \n",
    "        # Create list of indices\n",
    "        shuffle = np.arange(len(train_X))\n",
    "        \n",
    "        # Numpy shuffle method performs shuffle in place\n",
    "        np.random.shuffle(shuffle)\n",
    "        \n",
    "        # Shuffle the training data\n",
    "        train_X = np.squeeze(train_X[shuffle])\n",
    "        train_y = np.squeeze(train_y[shuffle])\n",
    "    \n",
    "        # Create RF model and train to extract features\n",
    "        RFclf = RandomForestClassifier(n_estimators = 300,\n",
    "                            bootstrap = True,\n",
    "                            max_depth = 10,\n",
    "                            random_state=0,\n",
    "                            criterion = \"entropy\",\n",
    "                            class_weight = \"balanced_subsample\",\n",
    "                            warm_start = False,\n",
    "                            n_jobs = -1,\n",
    "                            min_samples_leaf = 50,\n",
    "                            min_samples_split = 50,\n",
    "                            max_features = \"sqrt\"\n",
    "                            )\n",
    "\n",
    "        RFclf.fit(train_X, train_y)\n",
    "        \n",
    "        # Get accuracy on training and validation data\n",
    "        acc_train = RFclf.score(train_X, train_y)\n",
    "        acc_val = RFclf.score(valid_X, valid_y)\n",
    "        if verbose: \n",
    "            print(\"\\t RF model. Accuracy on train and valid: \", acc_train, acc_val)\n",
    "        \n",
    "        # Get prediction on the validation data\n",
    "        pred = RFclf.predict(valid_X)\n",
    "        \n",
    "        # Gather RF metrics\n",
    "        if verbose:\n",
    "            print(\"\\t Computing the RF model metrics.\")\n",
    "        RFacc = balanced_accuracy_score(valid_y, pred)        \n",
    "        RFprec = precision_score(valid_y, pred, average = None)\n",
    "        RFrec = recall_score(valid_y, pred, average = None)\n",
    "        RFf1 = f1_score(valid_y, pred, average = None)\n",
    "        RFconf = confusion_matrix(valid_y, pred, normalize='true')\n",
    "        RFmetrics.append([RFacc, RFprec, RFrec, RFf1, RFconf])\n",
    "        \n",
    "        if verbose: \n",
    "            print(\"\\t RF score:    \", RFclf.score(valid_X, valid_y))\n",
    "            print(\"\\t RF accuracy: \", RFacc)\n",
    "            print(\"\\t RF precision:\", RFprec)\n",
    "            print(\"\\t RF recall:   \", RFrec)\n",
    "            print(\"\\t RF F1:       \", RFf1)\n",
    "            print(\"\\t RF confusion matrix:\\n\", RFconf)           \n",
    "        \n",
    "        # Save the model\n",
    "        joblib.dump(RFclf, SIX_CLASSIFIER_PATH+\"RF_\" + CV_fold_name + \".RFmod\")\n",
    "        \n",
    "        # Save the feature importance vector\n",
    "         \n",
    "        # get a selector on the top 20 features\n",
    "        selector = SelectFromModel(RFclf, prefit=True, threshold=-np.inf, max_features=20)\n",
    "        del RFclf\n",
    "        \n",
    "        # project the training and the validation data\n",
    "        sel_train_data=selector.transform(train_X)\n",
    "        sel_valid_data=selector.transform(valid_X)\n",
    "        \n",
    "        #train a new SVC model on the reduced features\n",
    "        from sklearn.svm import SVC\n",
    "\n",
    "        # Create a classifier: a support vector RBF classifier\n",
    "\n",
    "        SVCclf = SVC(C=1.0, kernel='rbf', gamma='scale',\n",
    "                  probability=False, \n",
    "                  class_weight='balanced', \n",
    "                  decision_function_shape='ovo',\n",
    "                  random_state = 0)\n",
    "\n",
    "        SVCclf.fit(sel_train_data, train_y)\n",
    "        \n",
    "        # Get accuracy on training and validation data\n",
    "        acc_sel_train = SVCclf.score(sel_train_data, train_y)\n",
    "        acc_sel_val = SVCclf.score(sel_valid_data, valid_y)\n",
    "        if verbose: \n",
    "            print(\"\\t Reduced SVC model. Accuracy on train and valid: \", acc_sel_train, acc_sel_val)\n",
    "        \n",
    "        # save the model to disk\n",
    "        joblib.dump(SVCclf, SIX_CLASSIFIER_PATH + \"SVC_\" + CV_fold_name + \".SVCmod\")\n",
    "        \n",
    "        # Get prediction on all spectra\n",
    "        pred = SVCclf.predict(sel_valid_data)\n",
    "        \n",
    "        # Gather SVC metrics\n",
    "        if verbose:\n",
    "            print(\"\\t Computing the SVC model metrics.\")\n",
    "        SVCacc = balanced_accuracy_score(valid_y, pred)        \n",
    "        SVCprec = precision_score(valid_y, pred, average = None)\n",
    "        SVCrec = recall_score(valid_y, pred, average = None)\n",
    "        SVCf1 = f1_score(valid_y, pred, average = None)\n",
    "        SVCconf = confusion_matrix(valid_y, pred, normalize='true')\n",
    "        SVCmetrics.append([SVCacc, SVCprec, SVCrec, SVCf1, SVCconf])\n",
    "        \n",
    "        if verbose: \n",
    "            print(\"\\t SVC accuracy: \", SVCacc)\n",
    "            print(\"\\t SVC precision:\", SVCprec)\n",
    "            print(\"\\t SVC recall:   \", SVCrec)\n",
    "            print(\"\\t SVC F1:       \", SVCf1)\n",
    "            print(\"\\t SVC confusion matrix:\\n\", SVCconf)          \n",
    "        \n",
    "        # Clear memory\n",
    "        del SVCclf\n",
    "        del train_X\n",
    "        del train_y\n",
    "        del valid_X\n",
    "        del valid_y\n",
    "        del sel_train_data\n",
    "        del sel_valid_data\n",
    "        gc.collect()\n",
    "        \n",
    "    return RFmetrics, SVCmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample ignored: HF-1887_via-t_2_1.h5_3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the pre-processed data and the tumor map of each sample\n",
    "samples_0 = np.load(PREPROC_DATA_PATH, allow_pickle=True)\n",
    "tumor_map_0 = np.load(TUMOR_MAP_PATH, allow_pickle=True)\n",
    "\n",
    "samples = []\n",
    "labels=[]\n",
    "\n",
    "# Filter the data: retain only the tumor spots, based on the tumor map  \n",
    "# Flatten the data (no spatial info needed here) \n",
    "# Skip the samples on the \"ignore\" list\n",
    "\n",
    "for (sample, tumor) in zip(samples_0, tumor_map_0):\n",
    "    if sample[SAMPLE_DICT_NAME_KEY] in ignore:\n",
    "        print(\"Sample ignored:\", sample[SAMPLE_DICT_NAME_KEY])\n",
    "        continue    \n",
    "    \n",
    "    sample[SAMPLE_DICT_DATA_KEY] = sample[SAMPLE_DICT_DATA_KEY].reshape(-1, sample[SAMPLE_DICT_DATA_KEY].shape[2])\n",
    "    tumor.resize(np.product(tumor.shape))\n",
    "    sample[SAMPLE_DICT_DATA_KEY] = sample[SAMPLE_DICT_DATA_KEY][tumor == 1]\n",
    "    samples.append(sample)\n",
    "    \n",
    "    # Set the methylation label \n",
    "    label = sample[SAMPLE_DICT_CLASS_ID_KEY]\n",
    "    \n",
    "    # All spots get as label the methylation label of the entire sample\n",
    "    labels.append(label*np.ones(sample[SAMPLE_DICT_DATA_KEY].shape[0], dtype=int))\n",
    "    \n",
    "del samples_0\n",
    "del tumor_map_0\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation fold 1\n",
      "\t RF model. Accuracy on train and valid:  0.7163767824075211 0.2354011315247596\n",
      "\t Computing the RF model metrics.\n",
      "\t RF score:     0.2354011315247596\n",
      "\t RF accuracy:  0.2323382614997261\n",
      "\t RF precision: [0.004 0.743 0.029 0.266 0.229 0.102]\n",
      "\t RF recall:    [0.002 0.41  0.011 0.338 0.243 0.39 ]\n",
      "\t RF F1:        [0.002 0.528 0.015 0.298 0.236 0.161]\n",
      "\t RF confusion matrix:\n",
      " [[0.002 0.001 0.003 0.142 0.852 0.   ]\n",
      " [0.076 0.41  0.257 0.034 0.209 0.014]\n",
      " [0.014 0.069 0.011 0.412 0.148 0.347]\n",
      " [0.02  0.012 0.013 0.338 0.434 0.182]\n",
      " [0.045 0.019 0.086 0.181 0.243 0.426]\n",
      " [0.001 0.06  0.    0.277 0.271 0.39 ]]\n",
      "\t Reduced SVC model. Accuracy on train and valid:  0.6431402790944412 0.2824413746226585\n",
      "\t Computing the SVC model metrics.\n",
      "\t SVC accuracy:  0.3037162574790937\n",
      "\t SVC precision: [0.747 0.74  0.055 0.227 0.251 0.071]\n",
      "\t SVC recall:    [0.422 0.589 0.014 0.273 0.26  0.265]\n",
      "\t SVC F1:        [0.539 0.656 0.022 0.248 0.255 0.112]\n",
      "\t SVC confusion matrix:\n",
      " [[0.422 0.    0.001 0.209 0.367 0.001]\n",
      " [0.004 0.589 0.107 0.014 0.279 0.007]\n",
      " [0.019 0.105 0.014 0.417 0.114 0.331]\n",
      " [0.014 0.013 0.013 0.273 0.427 0.26 ]\n",
      " [0.008 0.044 0.108 0.188 0.26  0.393]\n",
      " [0.    0.024 0.    0.204 0.506 0.265]]\n",
      "Validation fold 2\n",
      "\t RF model. Accuracy on train and valid:  0.7033826874644569 0.28536637018212624\n",
      "\t Computing the RF model metrics.\n",
      "\t RF score:     0.28536637018212624\n",
      "\t RF accuracy:  0.20562425487882666\n",
      "\t RF precision: [0.001 0.595 0.    0.424 0.089 0.087]\n",
      "\t RF recall:    [0.    0.546 0.    0.457 0.041 0.189]\n",
      "\t RF F1:        [0.    0.57  0.    0.44  0.056 0.119]\n",
      "\t RF confusion matrix:\n",
      " [[0.    0.064 0.    0.    0.139 0.796]\n",
      " [0.023 0.546 0.397 0.016 0.009 0.009]\n",
      " [0.    0.447 0.    0.319 0.219 0.016]\n",
      " [0.158 0.002 0.06  0.457 0.255 0.068]\n",
      " [0.008 0.267 0.008 0.36  0.041 0.315]\n",
      " [0.093 0.001 0.095 0.492 0.13  0.189]]\n",
      "\t Reduced SVC model. Accuracy on train and valid:  0.5926659354943538 0.26951856557955667\n",
      "\t Computing the SVC model metrics.\n",
      "\t SVC accuracy:  0.17544197392122785\n",
      "\t SVC precision: [0.001 0.575 0.001 0.421 0.084 0.004]\n",
      "\t SVC recall:    [0.001 0.546 0.002 0.467 0.031 0.007]\n",
      "\t SVC F1:        [0.001 0.56  0.001 0.443 0.045 0.005]\n",
      "\t SVC confusion matrix:\n",
      " [[0.001 0.31  0.012 0.007 0.074 0.597]\n",
      " [0.01  0.546 0.432 0.008 0.001 0.004]\n",
      " [0.    0.438 0.002 0.131 0.412 0.017]\n",
      " [0.255 0.058 0.027 0.467 0.189 0.004]\n",
      " [0.051 0.127 0.02  0.422 0.031 0.349]\n",
      " [0.314 0.075 0.043 0.52  0.041 0.007]]\n",
      "Validation fold 3\n",
      "\t RF model. Accuracy on train and valid:  0.6755602173149284 0.32935973851182465\n",
      "\t Computing the RF model metrics.\n",
      "\t RF score:     0.32935973851182465\n",
      "\t RF accuracy:  0.3137932624133807\n",
      "\t RF precision: [0.088 0.428 0.082 0.566 0.318 0.178]\n",
      "\t RF recall:    [0.123 0.56  0.024 0.572 0.387 0.217]\n",
      "\t RF F1:        [0.103 0.485 0.038 0.569 0.349 0.195]\n",
      "\t RF confusion matrix:\n",
      " [[0.123 0.678 0.077 0.011 0.    0.111]\n",
      " [0.076 0.56  0.056 0.099 0.167 0.042]\n",
      " [0.233 0.565 0.024 0.072 0.016 0.091]\n",
      " [0.059 0.005 0.046 0.572 0.14  0.178]\n",
      " [0.347 0.037 0.12  0.07  0.387 0.04 ]\n",
      " [0.1   0.033 0.32  0.016 0.314 0.217]]\n",
      "\t Reduced SVC model. Accuracy on train and valid:  0.6000549906566801 0.39322857492440266\n",
      "\t Computing the SVC model metrics.\n",
      "\t SVC accuracy:  0.3403241109448969\n",
      "\t SVC precision: [0.053 0.565 0.329 0.677 0.442 0.076]\n",
      "\t SVC recall:    [0.09  0.68  0.15  0.566 0.465 0.091]\n",
      "\t SVC F1:        [0.066 0.617 0.206 0.617 0.453 0.083]\n",
      "\t SVC confusion matrix:\n",
      " [[0.09  0.641 0.152 0.024 0.    0.093]\n",
      " [0.036 0.68  0.066 0.017 0.118 0.083]\n",
      " [0.379 0.334 0.15  0.039 0.    0.098]\n",
      " [0.179 0.004 0.004 0.566 0.076 0.171]\n",
      " [0.311 0.01  0.055 0.145 0.465 0.014]\n",
      " [0.114 0.02  0.455 0.018 0.302 0.091]]\n",
      "Validation fold 4\n",
      "\t RF model. Accuracy on train and valid:  0.6406310974555549 0.1807610373873786\n",
      "\t Computing the RF model metrics.\n",
      "\t RF score:     0.1807610373873786\n",
      "\t RF accuracy:  0.20312477724086453\n",
      "\t RF precision: [0.266 0.162 0.028 0.285 0.194 0.123]\n",
      "\t RF recall:    [0.161 0.235 0.061 0.381 0.022 0.358]\n",
      "\t RF F1:        [0.201 0.192 0.038 0.326 0.04  0.183]\n",
      "\t RF confusion matrix:\n",
      " [[0.161 0.569 0.152 0.064 0.    0.054]\n",
      " [0.274 0.235 0.221 0.007 0.045 0.217]\n",
      " [0.06  0.847 0.061 0.001 0.    0.031]\n",
      " [0.058 0.19  0.245 0.381 0.032 0.093]\n",
      " [0.232 0.032 0.019 0.554 0.022 0.141]\n",
      " [0.    0.019 0.426 0.042 0.155 0.358]]\n",
      "\t Reduced SVC model. Accuracy on train and valid:  0.5982533182507496 0.2355033517696953\n",
      "\t Computing the SVC model metrics.\n",
      "\t SVC accuracy:  0.2510724261599363\n",
      "\t SVC precision: [0.281 0.388 0.077 0.268 0.685 0.089]\n",
      "\t SVC recall:    [0.155 0.293 0.383 0.3   0.204 0.172]\n",
      "\t SVC F1:        [0.2   0.334 0.129 0.283 0.314 0.117]\n",
      "\t SVC confusion matrix:\n",
      " [[0.155 0.001 0.752 0.037 0.    0.056]\n",
      " [0.287 0.293 0.3   0.002 0.018 0.1  ]\n",
      " [0.093 0.517 0.383 0.001 0.    0.007]\n",
      " [0.042 0.348 0.117 0.3   0.093 0.101]\n",
      " [0.162 0.022 0.028 0.485 0.204 0.101]\n",
      " [0.002 0.034 0.591 0.126 0.075 0.172]]\n",
      "Validation fold 5\n",
      "\t RF model. Accuracy on train and valid:  0.7244054134739775 0.2978832560614122\n",
      "\t Computing the RF model metrics.\n",
      "\t RF score:     0.2978832560614122\n",
      "\t RF accuracy:  0.24342914802839144\n",
      "\t RF precision: [0.311 0.852 0.018 0.078 0.384 0.084]\n",
      "\t RF recall:    [0.17  0.634 0.006 0.209 0.223 0.219]\n",
      "\t RF F1:        [0.219 0.727 0.009 0.114 0.282 0.122]\n",
      "\t RF confusion matrix:\n",
      " [[0.17  0.001 0.012 0.396 0.421 0.001]\n",
      " [0.063 0.634 0.049 0.213 0.01  0.032]\n",
      " [0.017 0.054 0.006 0.482 0.113 0.329]\n",
      " [0.009 0.098 0.284 0.209 0.103 0.296]\n",
      " [0.017 0.034 0.044 0.533 0.223 0.149]\n",
      " [0.001 0.02  0.    0.691 0.07  0.219]]\n",
      "\t Reduced SVC model. Accuracy on train and valid:  0.6486167777888348 0.3181006308428973\n",
      "\t Computing the SVC model metrics.\n",
      "\t SVC accuracy:  0.25335847257402466\n",
      "\t SVC precision: [0.367 0.775 0.063 0.054 0.419 0.098]\n",
      "\t SVC recall:    [0.126 0.634 0.011 0.13  0.373 0.247]\n",
      "\t SVC F1:        [0.187 0.697 0.018 0.076 0.394 0.14 ]\n",
      "\t SVC confusion matrix:\n",
      " [[0.126 0.001 0.002 0.511 0.357 0.003]\n",
      " [0.029 0.634 0.056 0.213 0.037 0.031]\n",
      " [0.019 0.084 0.011 0.347 0.124 0.416]\n",
      " [0.011 0.16  0.101 0.13  0.302 0.297]\n",
      " [0.008 0.066 0.007 0.512 0.373 0.035]\n",
      " [0.001 0.038 0.    0.645 0.069 0.247]]\n"
     ]
    }
   ],
   "source": [
    "reset_seed(2022)\n",
    "RFmetrics, SVCmetrics = CrossValidation(data=samples, labels=labels, CV_folds=CV5folds, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del samples\n",
    "del labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Mean RF accuracy:  0.23966194081223788\n",
      "\t Mean RF precision: [0.134 0.556 0.031 0.324 0.243 0.115]\n",
      "\t Mean RF recall:    [0.091 0.477 0.02  0.391 0.183 0.275]\n",
      "\t Mean RF F1:        [0.105 0.5   0.02  0.349 0.193 0.156]\n",
      "\t Mean RF confusion matrix:\n",
      " [[0.091 0.263 0.049 0.122 0.282 0.192]\n",
      " [0.102 0.477 0.196 0.074 0.088 0.063]\n",
      " [0.065 0.396 0.02  0.257 0.099 0.162]\n",
      " [0.061 0.061 0.13  0.391 0.193 0.164]\n",
      " [0.13  0.078 0.055 0.34  0.183 0.214]\n",
      " [0.039 0.027 0.168 0.304 0.188 0.275]]\n"
     ]
    }
   ],
   "source": [
    "results = np.mean(np.asanyarray(RFmetrics,dtype=object), axis=0)\n",
    "print(\"\\t Mean RF accuracy: \", results[0])\n",
    "print(\"\\t Mean RF precision:\", results[1])\n",
    "print(\"\\t Mean RF recall:   \", results[2])\n",
    "print(\"\\t Mean RF F1:       \", results[3])\n",
    "print(\"\\t Mean RF confusion matrix:\\n\", results[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Mean SVC accuracy:  0.26478264821583586\n",
      "\t Mean SVC precision: [0.29  0.609 0.105 0.33  0.376 0.068]\n",
      "\t Mean SVC recall:    [0.159 0.548 0.112 0.347 0.266 0.157]\n",
      "\t Mean SVC F1:        [0.199 0.573 0.075 0.333 0.292 0.092]\n",
      "\t Mean SVC confusion matrix:\n",
      " [[0.159 0.191 0.184 0.158 0.159 0.15 ]\n",
      " [0.073 0.548 0.192 0.051 0.091 0.045]\n",
      " [0.102 0.295 0.112 0.187 0.13  0.174]\n",
      " [0.1   0.117 0.052 0.347 0.217 0.167]\n",
      " [0.108 0.054 0.044 0.35  0.266 0.178]\n",
      " [0.086 0.038 0.218 0.303 0.199 0.157]]\n"
     ]
    }
   ],
   "source": [
    "results = np.mean(np.asanyarray(SVCmetrics,dtype=object), axis=0)\n",
    "print(\"\\t Mean SVC accuracy: \", results[0])\n",
    "print(\"\\t Mean SVC precision:\", results[1])\n",
    "print(\"\\t Mean SVC recall:   \", results[2])\n",
    "print(\"\\t Mean SVC F1:       \", results[3])\n",
    "print(\"\\t Mean SVC confusion matrix:\\n\", results[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
